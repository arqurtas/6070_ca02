{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rYDcd1dMUZ0",
    "outputId": "51203bb2-7e8b-4ced-9bb6-d19c64956d14"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4p_DvtT7sOIr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jjKF0nIMwz8_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "###In short terms the function below will create a dictionary of the most frequent 3000 words from emails\n",
    "def make_Dictionary(root_dir):#To a dictionary of found in root_dir\n",
    "  all_words = []  #empty list \n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #creates a list of email files stored within root_dir using a list comprehension\n",
    "  for mail in emails:\n",
    "    with open(mail) as m:\n",
    "      for line in m:\n",
    "        words = line.split()\n",
    "        all_words += words\n",
    "  dictionary = Counter(all_words)\n",
    "  list_to_remove = list(dictionary) ###goes through each and every mail within the file and adds it to the \"allwords\" empty list created previously\n",
    "\n",
    "  for item in list_to_remove:\n",
    "    if item.isalpha() == False:\n",
    "      del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]        ###above any non-alpha numeric number would then be deleted\n",
    "  dictionary = dictionary.most_common(3000)  \n",
    "  return dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dmVW5xNlyOFc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#The purpose of the function below is to analyze all the filmes names and decide weather it is considered spam or not\n",
    "## A feature matrix is also created which would host 3000 records similar to the length of the email file\n",
    "##train_labels are created to a similar length of the email file in which it would label weather the email is a spam or not\n",
    "def extract_features(mail_dir):\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "  train_labels = np.zeros(len(files))\n",
    "  count = 1;\n",
    "  docID = 0;\n",
    "  for fil in files:\n",
    "    with open(fil) as fi:\n",
    "      for i, line in enumerate(fi):\n",
    "        if i ==2:\n",
    "          words = line.split()\n",
    "          for word in words:\n",
    "            wordID = 0\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word:\n",
    "                wordID = i\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "      train_labels[docID] = 0;\n",
    "      filepathTokens = fil.split('/')\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1\n",
    "      docID = docID + 1\n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zoq-rE7Mx0pp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Path to both train-mails & test-mails files\n",
    "##By using './test-mails' this creates a relative path in witch any user who dowload the files can run it without altering any code\n",
    "\n",
    "#TRAIN_DIR = '/content/drive/MyDrive/6070/ca02/train-mails'\n",
    "#TEST_DIR = '/content/drive/MyDrive/6070/ca02/test-mails'\n",
    "\n",
    "TRAIN_DIR = './train-mails'\n",
    "TEST_DIR = './test-mails'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "134lmhauyQxE",
    "outputId": "0005f17e-9d07-484d-ede3-ad6d024b340c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "#here a training dictionary is created\n",
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQN2gEfaLZKk",
    "outputId": "d17c1d5b-3cd0-4b28-cb91-7f7b81e5776f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naive Bayes algorithm.....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "Accuracy Score: 0.9653846153846154\n"
     ]
    }
   ],
   "source": [
    "# In this section enter your code to TRAIN the model using Naive Bayes algorithm, then PREDICT and then evaluate PERFORMANCE (Accuracy)\n",
    "\n",
    "##Using the fuctions created along with the downloaded email files\n",
    "###First a model.fit functions is used to train the model with the training dataset\n",
    "###Second it will score the test data by running both the trained model along with the test data set\n",
    "###In the end an accuracy is created that would evaluate the performance of the model itself\n",
    "model = GaussianNB() \n",
    "print (\"Training Model using Gaussian Naive Bayes algorithm.....\")\n",
    "model.fit(features_matrix, labels)\n",
    "print (\"Training completed\")\n",
    "\n",
    "print(\"testing trained model to predict Test Data labels\")\n",
    "\n",
    "predicted_labels = model.predict(test_features_matrix)\n",
    "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "\n",
    "print(f'Accuracy Score: {accuracy_score(test_labels, predicted_labels)}')\n",
    "#looking at the accuracy score the accuracy stands at 96.54% which is highly accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
